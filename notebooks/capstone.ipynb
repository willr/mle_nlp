{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import unidecode\n",
    "# import contractions\n",
    "import re\n",
    "# from word2number import w2n\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "# Keras package\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, Embedding, Dropout, Activation, LSTM, Lambda, Bidirectional\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize global variables\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 60  \n",
    "MAX_NUM_WORDS = 200000  # There are about 201000 unique words in training dataset, 200000 is enough for tokenization\n",
    "EMBEDDING_DIM = 300  # word-embedded-vector dimension(300 is for 'glove.42B.300d')\n",
    "N_HIDDEN = 512\n",
    "N_DENSE = 256\n",
    "\n",
    "DROPOUT_RATE_LSTM = 0.10 # drop-out possibility, random set to avoid outfitting\n",
    "DROPOUT_RATE_DENSE = 0.15\n",
    "\n",
    "ACTIVE_FUNC = 'relu'\n",
    "VERSION = 'bilstm3'\n",
    "\n",
    "PATH_TO_GLOVE_FILE = './data/glove.42B.300d.txt'\n",
    "# PATH_TO_GLOVE_FILE = './data/glove.840B.300d.txt'\n",
    "\n",
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes Hidden: 512\n",
      "Nodes Dense: 256\n",
      "Dropout Rate LSTM: 0.1\n",
      "Dropout Rate Dense: 0.15\n"
     ]
    }
   ],
   "source": [
    "print(f'Nodes Hidden: {N_HIDDEN}')\n",
    "print(f'Nodes Dense: {N_DENSE}')\n",
    "\n",
    "print(f'Dropout Rate LSTM: {DROPOUT_RATE_LSTM}')\n",
    "print(f'Dropout Rate Dense: {DROPOUT_RATE_DENSE}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create word embedding dictionary\n",
      "Found 1917494 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Create word embedding dictionary from 'glove.840B.300d.txt', {key:value} is {word: glove vector(300,)}\n",
    "print('Create word embedding dictionary')\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(PATH_TO_GLOVE_FILE) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "        \n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How do I read and find my YouTube comments?\n",
      "How can I see all my Youtube comments?\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>404346</th>\n",
       "      <td>404346</td>\n",
       "      <td>789792</td>\n",
       "      <td>789793</td>\n",
       "      <td>How many keywords are there in the Racket prog...</td>\n",
       "      <td>How many keywords are there in PERL Programmin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404347</th>\n",
       "      <td>404347</td>\n",
       "      <td>789794</td>\n",
       "      <td>789795</td>\n",
       "      <td>Do you believe there is life after death?</td>\n",
       "      <td>Is it true that there is life after death?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404348</th>\n",
       "      <td>404348</td>\n",
       "      <td>789796</td>\n",
       "      <td>789797</td>\n",
       "      <td>What is one coin?</td>\n",
       "      <td>What's this coin?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404349</th>\n",
       "      <td>404349</td>\n",
       "      <td>789798</td>\n",
       "      <td>789799</td>\n",
       "      <td>What is the approx annual cost of living while...</td>\n",
       "      <td>I am having little hairfall problem but I want...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404350</th>\n",
       "      <td>404350</td>\n",
       "      <td>789800</td>\n",
       "      <td>789801</td>\n",
       "      <td>What is like to have sex with cousin?</td>\n",
       "      <td>What is it like to have sex with your cousin?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "404346  404346  789792  789793   \n",
       "404347  404347  789794  789795   \n",
       "404348  404348  789796  789797   \n",
       "404349  404349  789798  789799   \n",
       "404350  404350  789800  789801   \n",
       "\n",
       "                                                question1  \\\n",
       "404346  How many keywords are there in the Racket prog...   \n",
       "404347          Do you believe there is life after death?   \n",
       "404348                                  What is one coin?   \n",
       "404349  What is the approx annual cost of living while...   \n",
       "404350              What is like to have sex with cousin?   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "404346  How many keywords are there in PERL Programmin...             0  \n",
       "404347         Is it true that there is life after death?             1  \n",
       "404348                                  What's this coin?             0  \n",
       "404349  I am having little hairfall problem but I want...             0  \n",
       "404350      What is it like to have sex with your cousin?             0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/questions.csv.zip')\n",
    "df.head(10)\n",
    "pair = df.iloc[11]\n",
    "print(pair['question1'])\n",
    "print(pair['question2'])\n",
    "print(pair['is_duplicate'])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id  qid1  qid2                                          question1  \\\n",
      "5    5    11    12  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
      "7    7    15    16                     How can I be a good geologist?   \n",
      "11  11    23    24        How do I read and find my YouTube comments?   \n",
      "12  12    25    26               What can make Physics easy to learn?   \n",
      "13  13    27    28        What was your first sexual experience like?   \n",
      "\n",
      "                                            question2  is_duplicate  \n",
      "5   I'm a triple Capricorn (Sun, Moon and ascendan...             1  \n",
      "7           What should I do to be a great geologist?             1  \n",
      "11             How can I see all my Youtube comments?             1  \n",
      "12            How can you make physics easy to learn?             1  \n",
      "13             What was your first sexual experience?             1  \n",
      "\n",
      "count: \n",
      "id              404351\n",
      "qid1            404351\n",
      "qid2            404351\n",
      "question1       404350\n",
      "question2       404349\n",
      "is_duplicate    404351\n",
      "dtype: int64\n",
      "\n",
      "sum is_duplicate: 149306\n"
     ]
    }
   ],
   "source": [
    "print(df[df['is_duplicate'] == 1].head())\n",
    "print(f'\\ncount: \\n{df.count()}')\n",
    "print(f\"\\nsum is_duplicate: {df['is_duplicate'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df['is_duplicate']\n",
    "# dft = df.drop('is_duplicate', axis=1)\n",
    "dft = df\n",
    "X_train, X_test, y_train, y_test = train_test_split(dft, y, test_size=0.1, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sum is_duplicate: 134382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id              363915\n",
       "qid1            363915\n",
       "qid2            363915\n",
       "question1       363914\n",
       "question2       363913\n",
       "is_duplicate    363915\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"\\nsum is_duplicate: {X_train['is_duplicate'].sum()}\")\n",
    "X_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              40436\n",
       "qid1            40436\n",
       "qid2            40436\n",
       "question1       40436\n",
       "question2       40436\n",
       "is_duplicate    40436\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_q1 = X_train['question1'].values\n",
    "train_q2 = X_train['question2'].values\n",
    "train_labels = X_train['is_duplicate'].values\n",
    "\n",
    "sample = X_test.sample(n=10000, random_state=42)\n",
    "test_q1 = X_test['question1'].values\n",
    "test_q2 = X_test['question2'].values\n",
    "test_labels = X_test['is_duplicate'].values\n",
    "test_ids = X_test['id'].values  # id.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset\n"
     ]
    }
   ],
   "source": [
    "# Preprocess text in dataset\n",
    "print('Processing text dataset')\n",
    "\n",
    "def text_to_wordlist(text):\n",
    "    \n",
    "    # split words\n",
    "    text = str(text).split()\n",
    "    \n",
    "    text = \" \".join(text)\n",
    "\n",
    "    # Use re to clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"what's\", \"what is \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\’s\", \" \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\'s\", \" \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"n't\", \" not \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\‘\", \" \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\’\", \" \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\\"\", \" \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\“\", \" \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\”\", \" \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\",\", \" \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\.\", \" \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"!\", \" ! \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\/\", \" \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\+\", \" + \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\-\", \" - \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\=\", \" = \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"'\", \" \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\":\", \" : \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text, re.IGNORECASE)\n",
    "    text = re.sub(r\" e g \", \" eg \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\" b g \", \" bg \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\" u s \", \" american \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"j k\", \"jk\", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\？\", \" \", text, re.IGNORECASE)\n",
    "    \n",
    "    # Return a list of words\n",
    "    return(text)\n",
    "\n",
    "train_text_q1 = [] # preprocessed text of q1\n",
    "train_text_q2 = [] # preprocessed text of q2\n",
    "\n",
    "text_set = set() # complete set of words for building embeddings\n",
    "\n",
    "for text in train_q1:\n",
    "    tt = text_to_wordlist(text)\n",
    "    text_set.add(tt)\n",
    "    train_text_q1.append(tt)\n",
    "for text in train_q2:\n",
    "    tt = text_to_wordlist(text)\n",
    "    text_set.add(tt)\n",
    "    train_text_q2.append(tt)\n",
    "\n",
    "test_text_q1 = [] # preprocessed text of q1\n",
    "test_text_q2 = [] # preprocessed text of q2\n",
    "\n",
    "for text in test_q1:\n",
    "    tt = text_to_wordlist(text)\n",
    "    text_set.add(tt)\n",
    "    test_text_q1.append(tt)\n",
    "for text in test_q2:\n",
    "    tt = text_to_wordlist(text)\n",
    "    text_set.add(tt)\n",
    "    test_text_q2.append(tt)\n",
    "\n",
    "train_test_text = list(text_set)\n",
    "\n",
    "# vectorizer = TextVectorization(max_tokens=MAX_NUM_WORDS, output_sequence_length=EMBEDDING_DIM)\n",
    "# text_ds = tf.data.Dataset.from_tensor_slices(train_test_text).batch(128)\n",
    "# vectorizer.adapt(text_ds)\n",
    "# voc = vectorizer.get_vocabulary()\n",
    "# word_index = dict(zip(voc, range(len(voc))))\n",
    "# print(f'word_index len: {len(word_index)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86061 unique tokens are found\n",
      "Shape of train data tensor: (363915, 60)\n",
      "Shape of train labels tensor: (363915,)\n",
      "Shape of test data vtensor: (40436, 60)\n",
      "Shape of test ids tensor: (40436,)\n"
     ]
    }
   ],
   "source": [
    "# Keras.Tokenize for all text:\n",
    "# First construct a Tokenizer()\n",
    "# Then use tokenizer_on_texts() method to learn the dictionary of the corpus(all texts(sentences)). \n",
    "#    We can use .word_index to map between the each word (distinct) with the corresponding number.\n",
    "# Then use text_to_sequence() method to transfer every text(sentence) in texts into sequences of word_indexes.\n",
    "# Then add the same length by padding method: padding_sequences().\n",
    "# Finally use the embedding layer in keras to carry out a vectorization, and input it into LSTM.\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(train_text_q1 + train_text_q2 + test_text_q1 + test_text_q2)  # generate a token dictionary, \n",
    "\n",
    "train_sequences_1 = tokenizer.texts_to_sequences(train_text_q1)  # sequence of q1\n",
    "train_sequences_2 = tokenizer.texts_to_sequences(train_text_q2)  # sequence of q2\n",
    "test_sequences_1 = tokenizer.texts_to_sequences(test_text_q1)  # sequence of q1_test\n",
    "test_sequences_2 = tokenizer.texts_to_sequences(test_text_q2)  # sequence of q2_test\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('{} unique tokens are found'.format(len(word_index)))\n",
    "\n",
    "# Pad all train with Max_Sequence_Length: 60\n",
    "train_data_1 = pad_sequences(train_sequences_1, maxlen=MAX_SEQUENCE_LENGTH)  # padded_sequence of q1 as train_data\n",
    "train_data_2 = pad_sequences(train_sequences_2, maxlen=MAX_SEQUENCE_LENGTH)  # padded_sequence of q2 as train_data\n",
    "print('Shape of train data tensor:', train_data_1.shape)\n",
    "print('Shape of train labels tensor:', train_labels.shape)\n",
    "\n",
    "# Pad all test with Max_Sequence_Length\n",
    "test_data_1 = pad_sequences(test_sequences_1, maxlen=MAX_SEQUENCE_LENGTH)  # padded_sequence of q1_test as test_data\n",
    "test_data_2 = pad_sequences(test_sequences_2, maxlen=MAX_SEQUENCE_LENGTH)  # padded_sequence of q2_test as test_data\n",
    "print('Shape of test data vtensor:', test_data_2.shape)\n",
    "print('Shape of test ids tensor:', test_ids.shape)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 73278 words (12783 misses)\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 22:54:22.931221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-05 22:54:22.942441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-05 22:54:22.943032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-05 22:54:22.944017: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-05 22:54:22.945438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-05 22:54:22.946023: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-05 22:54:22.946569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-05 22:54:23.359244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-05 22:54:23.359787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-05 22:54:23.360288: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-05 22:54:23.360751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9613 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:43:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.layers import Dot\n",
    "\n",
    "num_tokens = len(word_index) + 2\n",
    "hits = 0\n",
    "misses = 0\n",
    "misses_txt = []\n",
    "\n",
    "def cosine_distance(vests):\n",
    "    x, y = vests\n",
    "    x = K.l2_normalize(x, axis=-1)\n",
    "    y = K.l2_normalize(y, axis=-1)\n",
    "    return -K.mean(x * y, axis=-1, keepdims=True)\n",
    "\n",
    "def cos_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0],1)\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    # print(embedding_vector.shape)\n",
    "    # if embedding_vector.shape[0] == 0:\n",
    "    #    print(f'word: {word}')\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "        misses_txt.append(word)\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))\n",
    "# print(f'misses: {misses_txt}')\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    EMBEDDING_DIM,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")\n",
    "\n",
    "# BiLSTM layer\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM\n",
    "lstm_layer = Bidirectional(LSTM(N_HIDDEN, dropout=DROPOUT_RATE_LSTM, recurrent_dropout=DROPOUT_RATE_LSTM))\n",
    "\n",
    "\n",
    "# Define inputs\n",
    "seq1 = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "seq2 = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "\n",
    "# Run inputs through embedding\n",
    "emb1 = embedding_layer(seq1)\n",
    "emb2 = embedding_layer(seq2)\n",
    "\n",
    "# Run through LSTM layers\n",
    "lstm_a = lstm_layer(emb1)\n",
    "lstm_b = lstm_layer(emb2)\n",
    "\n",
    "# cosin_sim_func = Lambda(cosine_distance, output_shape=cos_dist_output_shape)([lstm_a, lstm_b])\n",
    "dotted = Dot(axes=-1, normalize=True)([lstm_a, lstm_b])\n",
    "\n",
    "l1_norm = lambda x: 1 - K.abs(x[0] - x[1])\n",
    "l1_dist = Lambda(function=l1_norm, output_shape=lambda x: x[0], name='L1_distance')([lstm_a, lstm_b])\n",
    "\n",
    "merged = concatenate([lstm_a, lstm_b, l1_dist, dotted])\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dropout(DROPOUT_RATE_DENSE)(merged)\n",
    "\n",
    "merged = Dense(N_DENSE, activation=ACTIVE_FUNC)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dropout(DROPOUT_RATE_DENSE)(merged)\n",
    "\n",
    "merged = Dense(N_DENSE, activation=ACTIVE_FUNC)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dropout(DROPOUT_RATE_DENSE)(merged)\n",
    "\n",
    "merged = Dense(N_DENSE, activation=ACTIVE_FUNC)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dropout(DROPOUT_RATE_DENSE)(merged)\n",
    "\n",
    "merged = Dense(N_DENSE, activation=ACTIVE_FUNC)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dropout(DROPOUT_RATE_DENSE)(merged)\n",
    "\n",
    "preds = Dense(1, activation='sigmoid')(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 60)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 60)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 60, 300)      25818900    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 1024)         3330048     embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "L1_distance (Lambda)            (None, 1024)         0           bidirectional[0][0]              \n",
      "                                                                 bidirectional[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1)            0           bidirectional[0][0]              \n",
      "                                                                 bidirectional[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3073)         0           bidirectional[0][0]              \n",
      "                                                                 bidirectional[1][0]              \n",
      "                                                                 L1_distance[0][0]                \n",
      "                                                                 dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 3073)         12292       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 3073)         0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          786944      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256)          1024        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 256)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          65792       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 256)          1024        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            257         dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 30,149,913\n",
      "Trainable params: 4,322,819\n",
      "Non-trainable params: 25,827,094\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# def auroc(y_true, y_pred):\n",
    "#     return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)\n",
    "\n",
    "bst_model_path = VERSION + '.h5' \n",
    "\n",
    "model = Model(inputs=[seq1, seq2], outputs=preds)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# Summerization of model\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the model training\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 22:54:24.300012: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2559/2559 [==============================] - 1412s 549ms/step - loss: 0.4589 - acc: 0.7732 - val_loss: 0.4133 - val_acc: 0.8014\n",
      "Epoch 2/25\n",
      "2559/2559 [==============================] - 1407s 550ms/step - loss: 0.3705 - acc: 0.8270 - val_loss: 2.4091 - val_acc: 0.6282\n",
      "Epoch 3/25\n",
      "2559/2559 [==============================] - 1412s 552ms/step - loss: 0.3289 - acc: 0.8511 - val_loss: 0.3738 - val_acc: 0.8343\n",
      "Epoch 4/25\n",
      "2559/2559 [==============================] - 1409s 550ms/step - loss: 0.2939 - acc: 0.8690 - val_loss: 0.3343 - val_acc: 0.8438\n",
      "Epoch 5/25\n",
      "2559/2559 [==============================] - 1416s 554ms/step - loss: 0.2634 - acc: 0.8853 - val_loss: 0.3242 - val_acc: 0.8586\n",
      "Epoch 6/25\n",
      "2559/2559 [==============================] - 1413s 552ms/step - loss: 0.2362 - acc: 0.8988 - val_loss: 0.3024 - val_acc: 0.8663\n",
      "Epoch 7/25\n",
      "2559/2559 [==============================] - 1413s 552ms/step - loss: 0.2164 - acc: 0.9080 - val_loss: 0.3092 - val_acc: 0.8683\n",
      "Epoch 8/25\n",
      "2559/2559 [==============================] - 1413s 552ms/step - loss: 0.1962 - acc: 0.9175 - val_loss: 0.3428 - val_acc: 0.8592\n",
      "Epoch 9/25\n",
      "2559/2559 [==============================] - 1417s 554ms/step - loss: 0.1797 - acc: 0.9253 - val_loss: 0.3323 - val_acc: 0.8627\n"
     ]
    }
   ],
   "source": [
    "# print(f'embedding misses: {misses_txt}')\n",
    "\n",
    "print('Starting the model training')\n",
    "# Set early stopping (large patience should be useful)\n",
    "early_stopping =EarlyStopping(monitor='val_loss', patience=3)\n",
    "model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "hist = model.fit([train_data_1, train_data_2], train_labels, \\\n",
    "        validation_split=.1, \\\n",
    "        epochs=25, batch_size=128, shuffle=True, \\\n",
    "        callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "model.load_weights(bst_model_path) # sotre model parameters in .h5 file\n",
    "bst_val_score = min(hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-06 02:26:45.499811: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: bilstm3/assets\n",
      "size of tokenizer json: 7969149\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# save the model\n",
    "model.save(VERSION)\n",
    "tokenizer_json = tokenizer.to_json()\n",
    "print(f'size of tokenizer json: {len(tokenizer_json)}')\n",
    "with open(f'tokenizer.{VERSION}.json', 'w') as token_json:\n",
    "    token_json.write(tokenizer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 60)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 60)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 60, 300)      25818900    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 1024)         3330048     embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "L1_distance (Lambda)            (None, 1024)         0           bidirectional[0][0]              \n",
      "                                                                 bidirectional[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1)            0           bidirectional[0][0]              \n",
      "                                                                 bidirectional[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3073)         0           bidirectional[0][0]              \n",
      "                                                                 bidirectional[1][0]              \n",
      "                                                                 L1_distance[0][0]                \n",
      "                                                                 dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 3073)         12292       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 3073)         0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          786944      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256)          1024        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 256)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          65792       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 256)          1024        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            257         dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 30,149,913\n",
      "Trainable params: 4,322,819\n",
      "Non-trainable params: 25,827,094\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "del model\n",
    "model = tf.keras.models.load_model(VERSION) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def tokenize_text(q1: str, q2: str, model_name: str):\n",
    "    # tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "    # tokenizer.fit_on_texts([q1, q2])  # generate a token dictionary\n",
    "    \n",
    "    with open(f'tokenizer.{model_name}.json', 'r') as f:\n",
    "        token_json = f.read()\n",
    "    tokenizer = keras.preprocessing.text.tokenizer_from_json(token_json)\n",
    "    \n",
    "    seq_q1 = tokenizer.texts_to_sequences([q1])\n",
    "    seq_q2 = tokenizer.texts_to_sequences([q2])\n",
    "\n",
    "    q1_data = pad_sequences(seq_q1, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    q2_data = pad_sequences(seq_q2, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "\n",
    "    return (q1_data, q2_data, word_index)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).split()\n",
    "    text = \" \".join(text)\n",
    "\n",
    "    # Use re to clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"what's\", \"what is \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\’s\", \" \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\'s\", \" \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"n't\", \" not \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\‘\", \" \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\’\", \" \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\\"\", \" \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\“\", \" \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\”\", \" \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\",\", \" \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\.\", \" \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"!\", \" ! \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\/\", \" \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\+\", \" + \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\-\", \" - \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\=\", \" = \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"'\", \" \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\":\", \" : \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text, re.IGNORECASE)\n",
    "    text = re.sub(r\" e g \", \" eg \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\" b g \", \" bg \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\" u s \", \" american \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"j k\", \"jk\", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text, re.IGNORECASE)\n",
    "    text = re.sub(r\"\\？\", \" \", text, re.IGNORECASE)\n",
    "\n",
    "    return text\n",
    "\n",
    "def get_model(model_name: str):\n",
    "    global model\n",
    "    if model is None:\n",
    "        model = tf.keras.models.load_model(model_name) \n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict(q1: str, q2: str, model_name: str):\n",
    "    q1 = clean_text(q1)\n",
    "    q2 = clean_text(q2)\n",
    "\n",
    "    q1_data, q2_data, word_index = tokenize_text(q1, q2, model_name)\n",
    "    \n",
    "    model = get_model(model_name)\n",
    "    predictions = model([q1_data, q2_data])\n",
    "    print(f'q1: {q1}')\n",
    "    print(f'q2: {q2}')\n",
    "    print(f'same probabilty: {predictions}\\n' + '-' * 20)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "q1: What can make Physics easy to learn?\n",
      "q2: How can you make physics easy to learn?\n",
      "same probabilty: [[0.8847427]]\n",
      "--------------------\n",
      "q1: What should I do to be a great geologist?\n",
      "q2: How can I be a good geologist?\n",
      "same probabilty: [[0.76968783]]\n",
      "--------------------\n",
      "q1: Do you believe there is life after death?\n",
      "q2: Is it true that there is life after death?\n",
      "same probabilty: [[0.9720581]]\n",
      "--------------------\n",
      "q1: How do I read and find my YouTube comments?\n",
      "q2: How can I see all my Youtube comments?\n",
      "same probabilty: [[0.8024525]]\n",
      "--------------------\n",
      "q1: How do I see the color blue?\n",
      "q2: How do I see the color blue?\n",
      "same probabilty: [[0.9968671]]\n",
      "--------------------\n",
      "q1: What is one coin?\n",
      "q2: What this coin?\n",
      "same probabilty: [[0.16731362]]\n",
      "--------------------\n",
      "q1: Why do girls want to be friends with the guy they reject?\n",
      "q2: How do guys feel after rejecting a girl?\n",
      "same probabilty: [[7.3990814e-05]]\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bilstm5'\n",
    "model = tf.keras.models.load_model(model_name) \n",
    "\n",
    "q1 = 'What can make Physics easy to learn?'\n",
    "q2 = 'How can you make physics easy to learn?'\n",
    "predict(q1, q2, model_name)\n",
    "# embed = get_word_embeddings()\n",
    "\n",
    "q1 = 'What should I do to be a great geologist?'\n",
    "q2 = 'How can I be a good geologist?'\n",
    "predict(q1, q2, model_name)\n",
    "\n",
    "# Do you believe there is life after death? \tIs it true that there is life after death? \t1\n",
    "q1 = 'Do you believe there is life after death?'\n",
    "q2 = 'Is it true that there is life after death?'\n",
    "predict(q1, q2, model_name)\n",
    "\n",
    "# How do I read and find my YouTube comments? How can I see all my Youtube comments? 1\n",
    "q1 = 'How do I read and find my YouTube comments?'\n",
    "q2 = 'How can I see all my Youtube comments?'\n",
    "predict(q1, q2, model_name)\n",
    "\n",
    "q1 = 'How do I see the color blue?'\n",
    "q2 = 'How do I see the color blue?'\n",
    "predict(q1, q2, model_name)\n",
    "\n",
    " # What is one coin? \tWhat's this coin? \t0\n",
    "q1 = 'What is one coin?'\n",
    "q2 = 'What\\'s this coin?'\n",
    "predict(q1, q2, model_name)\n",
    "\n",
    "# Why do girls want to be friends with the guy they reject? How do guys feel after rejecting a girl? 0\n",
    "q1 = 'Why do girls want to be friends with the guy they reject?'\n",
    "q2 = 'How do guys feel after rejecting a girl?'\n",
    "predict(q1, q2, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "q1: What can make Physics easy to learn?\n",
      "q2: How can you make physics easy to learn?\n",
      "same probabilty: [[0.843715]]\n",
      "--------------------\n",
      "q1: What should I do to be a great geologist?\n",
      "q2: How can I be a good geologist?\n",
      "same probabilty: [[0.84447056]]\n",
      "--------------------\n",
      "q1: Do you believe there is life after death?\n",
      "q2: Is it true that there is life after death?\n",
      "same probabilty: [[0.9288534]]\n",
      "--------------------\n",
      "q1: How do I read and find my YouTube comments?\n",
      "q2: How can I see all my Youtube comments?\n",
      "same probabilty: [[0.88565695]]\n",
      "--------------------\n",
      "q1: How do I see the color blue?\n",
      "q2: How do I see the color blue?\n",
      "same probabilty: [[0.92360485]]\n",
      "--------------------\n",
      "q1: What is one coin?\n",
      "q2: What this coin?\n",
      "same probabilty: [[0.24006581]]\n",
      "--------------------\n",
      "q1: Why do girls want to be friends with the guy they reject?\n",
      "q2: How do guys feel after rejecting a girl?\n",
      "same probabilty: [[0.00982438]]\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bilstm3'\n",
    "model = tf.keras.models.load_model(model_name) \n",
    "\n",
    "q1 = 'What can make Physics easy to learn?'\n",
    "q2 = 'How can you make physics easy to learn?'\n",
    "predict(q1, q2, model_name)\n",
    "# embed = get_word_embeddings()\n",
    "\n",
    "q1 = 'What should I do to be a great geologist?'\n",
    "q2 = 'How can I be a good geologist?'\n",
    "predict(q1, q2, model_name)\n",
    "\n",
    "# Do you believe there is life after death? \tIs it true that there is life after death? \t1\n",
    "q1 = 'Do you believe there is life after death?'\n",
    "q2 = 'Is it true that there is life after death?'\n",
    "predict(q1, q2, model_name)\n",
    "\n",
    "# How do I read and find my YouTube comments? How can I see all my Youtube comments? 1\n",
    "q1 = 'How do I read and find my YouTube comments?'\n",
    "q2 = 'How can I see all my Youtube comments?'\n",
    "predict(q1, q2, model_name)\n",
    "\n",
    "q1 = 'How do I see the color blue?'\n",
    "q2 = 'How do I see the color blue?'\n",
    "predict(q1, q2, model_name)\n",
    "\n",
    " # What is one coin? \tWhat's this coin? \t0\n",
    "q1 = 'What is one coin?'\n",
    "q2 = 'What\\'s this coin?'\n",
    "predict(q1, q2, model_name)\n",
    "\n",
    "# Why do girls want to be friends with the guy they reject? How do guys feel after rejecting a girl? 0\n",
    "q1 = 'Why do girls want to be friends with the guy they reject?'\n",
    "q2 = 'How do guys feel after rejecting a girl?'\n",
    "predict(q1, q2, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "q1: What can make Physics easy to learn?\n",
      "q2: How can you make physics easy to learn?\n",
      "same probabilty: [[0.9345015]]\n",
      "--------------------\n",
      "q1: What should I do to be a great geologist?\n",
      "q2: How can I be a good geologist?\n",
      "same probabilty: [[0.8976296]]\n",
      "--------------------\n",
      "q1: Do you believe there is life after death?\n",
      "q2: Is it true that there is life after death?\n",
      "same probabilty: [[0.9052738]]\n",
      "--------------------\n",
      "q1: How do I read and find my YouTube comments?\n",
      "q2: How can I see all my Youtube comments?\n",
      "same probabilty: [[0.9159307]]\n",
      "--------------------\n",
      "q1: How do I see the color blue?\n",
      "q2: How do I see the color blue?\n",
      "same probabilty: [[0.9665545]]\n",
      "--------------------\n",
      "q1: What is one coin?\n",
      "q2: What this coin?\n",
      "same probabilty: [[0.07237303]]\n",
      "--------------------\n",
      "q1: Why do girls want to be friends with the guy they reject?\n",
      "q2: How do guys feel after rejecting a girl?\n",
      "same probabilty: [[0.00618028]]\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bilstm10'\n",
    "model = tf.keras.models.load_model(model_name) \n",
    "\n",
    "q1 = 'What can make Physics easy to learn?'\n",
    "q2 = 'How can you make physics easy to learn?'\n",
    "predict(q1, q2, model_name)\n",
    "# embed = get_word_embeddings()\n",
    "\n",
    "q1 = 'What should I do to be a great geologist?'\n",
    "q2 = 'How can I be a good geologist?'\n",
    "predict(q1, q2, model_name)\n",
    "\n",
    "# Do you believe there is life after death? \tIs it true that there is life after death? \t1\n",
    "q1 = 'Do you believe there is life after death?'\n",
    "q2 = 'Is it true that there is life after death?'\n",
    "predict(q1, q2, model_name)\n",
    "\n",
    "# How do I read and find my YouTube comments? How can I see all my Youtube comments? 1\n",
    "q1 = 'How do I read and find my YouTube comments?'\n",
    "q2 = 'How can I see all my Youtube comments?'\n",
    "predict(q1, q2, model_name)\n",
    "\n",
    "q1 = 'How do I see the color blue?'\n",
    "q2 = 'How do I see the color blue?'\n",
    "predict(q1, q2, model_name)\n",
    "\n",
    " # What is one coin? \tWhat's this coin? \t0\n",
    "q1 = 'What is one coin?'\n",
    "q2 = 'What\\'s this coin?'\n",
    "predict(q1, q2, model_name)\n",
    "\n",
    "# Why do girls want to be friends with the guy they reject? How do guys feel after rejecting a girl? 0\n",
    "q1 = 'Why do girls want to be friends with the guy they reject?'\n",
    "q2 = 'How do guys feel after rejecting a girl?'\n",
    "predict(q1, q2, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dup-question",
   "language": "python",
   "name": "dup-question"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
